---
title: "Figures"
author: "Masatoshi Katabuchi"
date: "`r format(Sys.time(), '%B %d, %Y')`"
fontsize: 11pt
format:
  html:
    theme: spacelab #readable #sandstone #spacelab #flatly
    toc: true
    toc-depth: 2
    toc-title: Contents
    self-contained: true
    smooth-scroll: true
    highlight-style: github
---

```{r global_options, include=FALSE}
library(knitr)
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  message = FALSE,
  cache = FALSE,
  fig.align = "center",
  fig.show = "hold"
)
```

```{r,include=FALSE}
library(tidyverse)
library(tarchetypes)
library(here)
library(kableExtra)
library(targets)
source(here("R", "stan.R"))
```

```{r}
d <- read_csv(here("data-raw/calibration_raw_data.csv")) |>
  janitor::clean_names()

data <- d |>
  mutate(fd = ifelse(is.na(fd), removed_fd, fd)) |>
  mutate(k = ifelse(is.na(k), removed_k, k)) |>
  filter(!is.na(fd)) |>
  filter(!is.na(k)) |>
  filter(k != 0) |>
  mutate(sp_id = species_name) |>
  mutate(sample_id = as.factor(sample_number))

```

# Note

- When there is a positive correlation between Fd and $\Delta$P, it is kind of obvious that there is also a positive correlation between K and $\Delta$P because Fd and K are supposed to be follow Grainer's equation ($Fd = a\times K^b \times exp(\epsilon)$, where $\epsilon$ is an error).

- As long as I have checked the relationships between log(K) and $\Delta$P and between log(Fd) and $\Delta$P for each sample, they are linear.

- Different samples show different relationships between log(K) and $\Delta$P, between log(Fd) and $\Delta$P, and between log(Fd) and log(K).

- Based on these, there are no break points for the relationships between log(Fd) and log(K), and thus it is better to use the largest pressure range in our data to estimate "a" and "b".

- We can also estimate "a" and "b" using Ec data.

- Since different samples align on different lines on the relationship of Fd and K, the error structure of this data is not purely linear (i.e., $Fd = a\times K^b \times exp(\epsilon)$) and it is more like non-linear (i.e., $Fd = a \times K^b + \epsilon$).


Fitting Fd = a * K^b * error to each subset of data based on the ranges of pressure gradients (e.g., 0.01-0.02, 0.01-0.05, 0.01-0.08) is problematic because 1) data with smaller ranges will always have smaller numbers of samples and 2) predictor value K will be biased towards smaller values.
The number of samples can be controlled using bootstrap or something but I'm not sure how to solve the latter problem at the moment.
Unless these issues are addressed, the current hypothesis H2 sounds like a trivial and statistical artifact and also not testable.

As long as I did a quick simulation by generating random variables that follows a normal distribution on the log-scale (i.e., linear) or log-normal distribution with additive errors (i.e., non-linear) , data with restricted ranges of predictor values tend to show smaller intercept (i.e., log_a) especially when data do not purely follow multiplicative error structure (i.e., linear relationship).
Data in the real world has some noises and that's why we tend to get smaller log_a values for the smaller ranges of a pressure gradient.

I haven't tried Bayesian hierarchical models for this yet but it might solve the second problem above because we can model errors from different sources.
First, I need to do a more robust simulation to check if a Bayesian hierarchical model can address the second problem.
If the model works, I can apply the same Bayesian model to the sap flow data to test if the curve obtained from the realistic ranges of pressure gradients and the full ranges of pressure gradients are similar.

Alternatively, we can estimate breakpoints for the relationship between Fd and K using a piecewise regression.
We could address if data with low K (low delta P and low Fd) will show different fitted curves from those obtained from data with high K, although I guess there will be no break points.

Finally, we can also best estimate of "a" and "b" that can predict annual transpiration (Ec) if we include Ec in the Bayesian hierarchical model.

I wrote three options i) Bayesian hierarchical models, ii) piecewise regression and iii) Bayesian hierarchical models with Ec.
Please let me know your thoughts.



# Data

## Fd - K

Different samples show different relationship.

```{r, fig.width=10, fig.height=10}
data |>
  ggplot(aes(x = k, y = fd, col = sample_id)) +
  geom_point() +
  scale_y_log10() +
  scale_x_log10() +
  geom_smooth(aes(group = sample_id), se = FALSE, method = "lm") +
  facet_wrap(~ species_name, scale = "free") +
  theme_bw() +
  theme(legend.position =  "none")
```

```{r, fig.width=10, fig.height=10}
data |>
  ggplot(aes(x = k, y = fd, col = sample_id)) +
  geom_point() +
  # geom_smooth(aes(group = sample_id), se = FALSE) +
  facet_wrap(~ species_name, scale = "free") +
  theme_bw() +
  theme(legend.position =  "none")
```


```{r, fig.width=10, fig.height=10}
data |>
  ggplot(aes(x = k, y = fd)) +
  geom_point() +
  scale_y_log10() +
  scale_x_log10() +
  geom_smooth(se = FALSE, method = "lm") +
  facet_wrap(~ species_name, scale = "free") +
  theme_bw() +
  theme(legend.position =  "none")
```

## Fd - $\Delta$P

Different samples show different relationship.

```{r, fig.width=10, fig.height=10}
data |>
  ggplot(aes(x = p_2, y = fd, col = sample_id)) +
  geom_point() +
  scale_y_log10() +
  # scale_x_log10() +
  geom_smooth(aes(group = sample_id), se = FALSE, method = "lm") +
  facet_wrap(~ species_name, scale = "free") +
  ylab("delta p") +
  theme_bw() +
  theme(legend.position =  "none")
```

```{r, fig.width=10, fig.height=10}
data |>
  ggplot(aes(x = p_2, y = fd)) +
  geom_point() +
  scale_y_log10() +
  # scale_x_log10() +
  geom_smooth(se = FALSE, method = "lm") +
  facet_wrap(~ species_name, scale = "free") +
  ylab("delta p") +
  theme_bw() +
  theme(legend.position =  "none")
```

## K - $\Delta$P

Different samples show different relationship.

```{r, fig.width=10, fig.height=10}
data |>
  ggplot(aes(x = p_2, y = k, col = sample_id)) +
  geom_point() +
  scale_y_log10() +
  # scale_x_log10() +
  geom_smooth(aes(group = sample_id), se = FALSE, method = "lm") +
  facet_wrap(~ species_name, scale = "free") +
  ylab("delta p") +
  theme_bw() +
  theme(legend.position =  "none")
```

```{r, fig.width=10, fig.height=10}
data |>
  ggplot(aes(x = p_2, y = k)) +
  geom_point() +
  scale_y_log10() +
  # scale_x_log10() +
  geom_smooth(se = FALSE, method = "lm") +
  facet_wrap(~ species_name, scale = "free") +
  ylab("delta p") +
  theme_bw() +
  theme(legend.position =  "none")
```

# Dummy data

```{r}
set.seed(123)
n_samp <- 10
xx <- seq(0.1, 0.8, by = 0.1)
n_rep <- length(xx)
sig <- rnorm(n_samp, 0, 0.5)
y_fun <- \(x) exp(xx) + x
z <- map(as.list(sig), y_fun) |> unlist()
tmp <- tibble(z,
              x = rep(xx, n_samp),
              samp = rep(paste0("samp", 1:n_samp), each = n_rep))


p1 <- tmp |>
  ggplot(aes(x = x, y = log(z), col = samp)) +
  geom_line() #+
  # xlab("Conspecific density") +
  # ylab("Survival rates") +
  # theme(legend.position = c(0.8, 0.7))
p1

```
